import streamlit as st
import requests

# ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜ã®è¡¨ç¤º
st.title("ğŸ’¬ Gemini ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
st.write("ã“ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯ã€Google ã® Gemini API ã‚’åˆ©ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

# Streamlit Community Cloudã®Secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
# .streamlit/secrets.toml ã« GEMINI_API_KEY = "YOUR_API_KEY" ã‚’è¨­å®šã—ã¦ãã ã•ã„
gemini_api_key = st.secrets.get("GEMINI_API_KEY")

if not gemini_api_key:
    st.info("Streamlit Community Cloudã®Secretsã« `GEMINI_API_KEY` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚", icon="ğŸ—ï¸")
else:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
    model_name = st.selectbox(
        "ä½¿ç”¨ã™ã‚‹ Gemini ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        (
            "gemini-2.5-flash", 
            "gemini-2.5-pro",
            "gemini-3-flash-preview", 
            "gemini-3-pro-preview"
        )
    )
    st.write(f"ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«: **{model_name}**")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # æ—¢å­˜ã®ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã™ã‚‹ãŸã‚ã®ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    if prompt := st.chat_input("ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›"):

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜ãƒ»è¡¨ç¤º
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Gemini APIç”¨ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã‚’æº–å‚™
        gemini_messages = []
        for m in st.session_state.messages:
            api_role = "user" if m["role"] == "user" else "model"
            gemini_messages.append(
                {
                    "role": api_role,
                    "parts": [{"text": m["content"]}]
                }
            )

        # APIã‚­ãƒ¼ã‚’å«ã¾ãªã„ã‚¯ãƒªãƒ¼ãƒ³ãªURLã‚’å®šç¾©
        api_url = f"https://generativelanguage.googleapis.com/v1/models/{model_name}:generateContent"

        # ãƒ˜ãƒƒãƒ€ãƒ¼ã« Content-Type ã¨ APIã‚­ãƒ¼ã‚’å«ã‚ã‚‹
        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": gemini_api_key 
        }
        
        data = {
            "contents": gemini_messages,
            "generationConfig": {
                "temperature": 0.7,
                "topP": 0.8
                # maxOutputTokens ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ (8192 ãªã©) ãŒé©ç”¨ã•ã‚Œã‚‹
            }
        }

        try:
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒŠå†…ã«è¡¨ç¤º
            with st.chat_message("assistant"):
                with st.spinner(f"{model_name} ãŒå¿œç­”ã‚’ç”Ÿæˆä¸­..."):
                    response = requests.post(api_url, headers=headers, json=data, timeout=30)
                    response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿ
                    
                    result = response.json()
                    
                    # APIã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã®ãƒã‚§ãƒƒã‚¯ã¨å¿œç­”ã®å–å¾—
                    if "candidates" in result and result["candidates"]:
                        candidate = result["candidates"][0]
                        
                        # ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™è¶…éã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ç¶­æŒ
                        if candidate.get("finishReason") == "MAX_TOKENS":
                            gemini_reply = f"å¿œç­”ãŒé€”ä¸­ã§çµ‚äº†ã—ã¾ã—ãŸï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™è¶…éï¼‰ã€‚ãƒ¢ãƒ‡ãƒ«ã®æœ€å¤§å‡ºåŠ›ãŒå°½ããŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                        elif "content" in candidate and "parts" in candidate["content"] and candidate["content"]["parts"]:
                            gemini_reply = candidate["content"]["parts"][0]["text"]
                        else:
                            # ãã®ä»–ã®äºˆæœŸã—ãªã„å¿œç­”å½¢å¼
                            gemini_reply = f"ã‚¨ãƒ©ãƒ¼: äºˆæœŸã—ãªã„APIå¿œç­”å½¢å¼ã§ã™ã€‚è©³ç´°: {result}"
                    else:
                        gemini_reply = f"ã‚¨ãƒ©ãƒ¼: å¿œç­”ã«å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è©³ç´°: {result}"

                    st.markdown(gemini_reply)
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
            st.session_state.messages.append({"role": "assistant", "content": gemini_reply})

        except requests.exceptions.RequestException as e:
            error_message = f"APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
            st.error(error_message)
            st.session_state.messages.append({"role": "assistant", "content": error_message})
        except Exception as e:
            error_message = f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
            st.error(error_message)
            st.session_state.messages.append({"role": "assistant", "content": error_message})
            
